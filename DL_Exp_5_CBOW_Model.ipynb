{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0kaUONaxSN1"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pylab as pylab\n",
        "import numpy as np\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKHoFmmNxSN_"
      },
      "outputs": [],
      "source": [
        "#Data Prepration\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tEaSiDqAxSOB"
      },
      "outputs": [],
      "source": [
        "sentences = \"\"\"We are about to study the idea of a computational process.\n",
        "Computational processes are abstract beings that inhabit computers.\n",
        "As they evolve, processes manipulate other abstract things called data.\n",
        "The evolution of a process is directed by a pattern of rules\n",
        "called a program. People create programs to direct processes. In effect,\n",
        "we conjure the spirits of the computer with our spells.\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hj3Tj0wWxSOC"
      },
      "source": [
        "Clean Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "raLmJGMHxSOM"
      },
      "outputs": [],
      "source": [
        "# remove special characters\n",
        "sentences = re.sub('[^A-Za-z0-9]+', ' ', sentences)\n",
        "\n",
        "# remove 1 letter words\n",
        "sentences = re.sub(r'(?:^| )\\w(?:$| )', ' ', sentences).strip()\n",
        "\n",
        "# lower all characters\n",
        "sentences = sentences.lower()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7l7U-kZxSOO"
      },
      "source": [
        "Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Vga-McNxSOP"
      },
      "outputs": [],
      "source": [
        "words = sentences.split()\n",
        "vocab = set(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4GJ4jQjZxSOQ"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(vocab)\n",
        "embed_dim = 10\n",
        "context_size = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJ48swukxSOR"
      },
      "source": [
        "Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHU-SHxnxSOT"
      },
      "outputs": [],
      "source": [
        "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
        "ix_to_word = {i: word for i, word in enumerate(vocab)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXEZSyOpxSOU"
      },
      "source": [
        "Data bags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcHv1QXmxSOV"
      },
      "outputs": [],
      "source": [
        "# data - [(context), target]\n",
        "\n",
        "data = []\n",
        "for i in range(2, len(words) - 2):\n",
        "    context = [words[i - 2], words[i - 1], words[i + 1], words[i + 2]]\n",
        "    target = words[i]\n",
        "    data.append((context, target))\n",
        "print(data[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJ-0_ufDxSOa"
      },
      "source": [
        "Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uku3xJzwxSOb"
      },
      "outputs": [],
      "source": [
        "embeddings =  np.random.random_sample((vocab_size, embed_dim))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NnXXnC8xSOc"
      },
      "source": [
        "Linear Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyAmpvpIxSOc"
      },
      "outputs": [],
      "source": [
        "def linear(m, theta):\n",
        "    w = theta\n",
        "    return m.dot(w)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6M-eSeDaxSOd"
      },
      "source": [
        "Log softmax + NLLloss = Cross Entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilM-2PVvxSOe"
      },
      "outputs": [],
      "source": [
        "def log_softmax(x):\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return np.log(e_x / e_x.sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVrb0p8XxSOf"
      },
      "outputs": [],
      "source": [
        "def NLLLoss(logs, targets):\n",
        "    out = logs[range(len(targets)), targets]\n",
        "    return -out.sum()/len(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6VjuBaRvxSOh"
      },
      "outputs": [],
      "source": [
        "def log_softmax_crossentropy_with_logits(logits,target):\n",
        "\n",
        "    out = np.zeros_like(logits)\n",
        "    out[np.arange(len(logits)),target] = 1\n",
        "\n",
        "    softmax = np.exp(logits) / np.exp(logits).sum(axis=-1,keepdims=True)\n",
        "\n",
        "    return (- out + softmax) / logits.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqWAlAiixSOi"
      },
      "source": [
        "Forward function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6jEHF5hxSOj"
      },
      "outputs": [],
      "source": [
        "def forward(context_idxs, theta):\n",
        "    m = embeddings[context_idxs].reshape(1, -1)\n",
        "    n = linear(m, theta)\n",
        "    o = log_softmax(n)\n",
        "\n",
        "    return m, n, o"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_f7Xtk6pxSOk"
      },
      "source": [
        "Backward function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGiXhv7fxSOl"
      },
      "outputs": [],
      "source": [
        "def backward(preds, theta, target_idxs):\n",
        "    m, n, o = preds\n",
        "\n",
        "    dlog = log_softmax_crossentropy_with_logits(n, target_idxs)\n",
        "    dw = m.T.dot(dlog)\n",
        "\n",
        "    return dw"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eeig5h-jxSOm"
      },
      "source": [
        "Optimize function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQNRvAxOxSOo"
      },
      "outputs": [],
      "source": [
        "def optimize(theta, grad, lr=0.03):\n",
        "    theta -= grad * lr\n",
        "    return theta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATRZMda6xSOp"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "geRxrJSlxSOq"
      },
      "outputs": [],
      "source": [
        "#Genrate training data\n",
        "\n",
        "theta = np.random.uniform(-1, 1, (2 * context_size * embed_dim, vocab_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PVG_kLF3xSOr"
      },
      "outputs": [],
      "source": [
        "epoch_losses = {}\n",
        "\n",
        "for epoch in range(80):\n",
        "\n",
        "    losses =  []\n",
        "\n",
        "    for context, target in data:\n",
        "        context_idxs = np.array([word_to_ix[w] for w in context])\n",
        "        preds = forward(context_idxs, theta)\n",
        "\n",
        "        target_idxs = np.array([word_to_ix[target]])\n",
        "        loss = NLLLoss(preds[-1], target_idxs)\n",
        "\n",
        "        losses.append(loss)\n",
        "\n",
        "        grad = backward(preds, theta, target_idxs)\n",
        "        theta = optimize(theta, grad, lr=0.03)\n",
        "\n",
        "\n",
        "    epoch_losses[epoch] = losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJDWhvcexSOs"
      },
      "source": [
        "Analyze"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hc2_6vtDxSOt"
      },
      "source": [
        "Plot loss/epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6qZ_WeexSOu"
      },
      "outputs": [],
      "source": [
        "ix = np.arange(0,80)\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.suptitle('Epoch/Losses', fontsize=20)\n",
        "plt.plot(ix,[epoch_losses[i][0] for i in ix])\n",
        "plt.xlabel('Epochs', fontsize=12)\n",
        "plt.ylabel('Losses', fontsize=12)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvAUOJ9NxSOv"
      },
      "source": [
        "Predict function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1ffANsexSOw"
      },
      "outputs": [],
      "source": [
        "def predict(words):\n",
        "    context_idxs = np.array([word_to_ix[w] for w in words])\n",
        "    preds = forward(context_idxs, theta)\n",
        "    word = ix_to_word[np.argmax(preds[-1])]\n",
        "\n",
        "    return word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzN6APcVxSOx"
      },
      "outputs": [],
      "source": [
        "# (['we', 'are', 'to', 'study'], 'about')\n",
        "predict(['we', 'are', 'to', 'study'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSt-tlrKxSOy"
      },
      "source": [
        "Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YaEsOtTxSOz"
      },
      "outputs": [],
      "source": [
        "def accuracy():\n",
        "    wrong = 0\n",
        "\n",
        "    for context, target in data:\n",
        "        if(predict(context) != target):\n",
        "            wrong += 1\n",
        "\n",
        "    return (1 - (wrong / len(data)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfn8u2XDxSO0"
      },
      "outputs": [],
      "source": [
        "accuracy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RYoa_DsxSO2"
      },
      "outputs": [],
      "source": [
        "predict(['processes', 'manipulate', 'things', 'study'])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}